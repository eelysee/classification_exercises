{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92b2d918-b055-4720-9e0b-cc22b9415fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import prepare\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from prepare import prep_titanic\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "seed = 55"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1c032f",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "In these exercises, we'll continue working with the titanic dataset and building logistic regression models. Throughout this exercise, be sure you are training, evaluation, and comparing models on the train and validate datasets. The test dataset should only be used for your final model.\n",
    "\n",
    "For all of the models you create, choose a threshold that optimizes for accuracy.\n",
    "\n",
    "Create a new notebook, logistic_regression, use it to answer the following questions:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecb34c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "titan = prep_titanic()\n",
    "titan['age'] = titan['age'].fillna(28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af4ecf70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train , val, test = prepare.train_val_test(titan , 'survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "749bea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = 1 - train.survived.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15e2bdc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>41.5792</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex   age  sibsp  parch      fare  embark_town  \\\n",
       "519         0       3    male  32.0      0      0    7.8958  Southampton   \n",
       "441         0       3    male  20.0      0      0    9.5000  Southampton   \n",
       "43          1       2  female   3.0      1      2   41.5792    Cherbourg   \n",
       "341         1       1  female  24.0      3      2  263.0000  Southampton   \n",
       "664         1       3    male  20.0      1      0    7.9250  Southampton   \n",
       "\n",
       "     alone  \n",
       "519      1  \n",
       "441      1  \n",
       "43       0  \n",
       "341      0  \n",
       "664      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af4ca34",
   "metadata": {},
   "source": [
    "#### 1. Create a model that includes only age, fare, and pclass. Does this model perform better than your baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8daa2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train[['age','fare', 'pclass']]\n",
    "y_train = train.survived\n",
    "x_val = val[['age','fare', 'pclass']]\n",
    "y_val = val.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb63f8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7142857142857143, 0.664179104477612)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg1 = LogisticRegression(random_state = seed, max_iter = 400)\n",
    "\n",
    "logreg1.fit(x_train, y_train)\n",
    "\n",
    "logreg1.score(x_train, y_train), logreg1.score(x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9969f4f1",
   "metadata": {},
   "source": [
    "They both perform better than baseline but only slightly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b527350a",
   "metadata": {},
   "source": [
    "#### 2. Include sex in your model as well. Note that you'll need to encode or create a dummy variable of this feature before including it in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c83fb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "titan = pd.get_dummies(titan, columns = ['sex'], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c8775a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train , val, test = prepare.train_val_test(titan , 'survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5689e8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train[['age','fare', 'pclass','sex_male']]\n",
    "y_train = train.survived\n",
    "x_val = val[['age','fare', 'pclass','sex_male']]\n",
    "y_val = val.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "defe74fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7784911717495987, 0.7761194029850746)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg2 = LogisticRegression(random_state = seed, max_iter = 400)\n",
    "\n",
    "logreg2.fit(x_train, y_train)\n",
    "\n",
    "logreg2.score(x_train, y_train), logreg2.score(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "340a17b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_train_2 = logreg2.predict(x_train)\n",
    "p_val_2 = logreg2.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416e4437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a9de5d1",
   "metadata": {},
   "source": [
    "#### 3. Try out other combinations of features and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ee06bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train[['pclass', 'alone','sex_male']]\n",
    "y_train = train.survived\n",
    "x_val = val[['pclass', 'alone','sex_male']]\n",
    "y_val = val.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "943c7927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7768860353130016, 0.7985074626865671)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg3 = LogisticRegression(random_state = seed, max_iter = 400)\n",
    "\n",
    "logreg3.fit(x_train, y_train)\n",
    "\n",
    "logreg3.score(x_train, y_train), logreg3.score(x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def0bbbf",
   "metadata": {},
   "source": [
    "Basic with everything but target and port."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80b8706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.drop(columns = ['survived','embark_town'])\n",
    "y_train = train.survived\n",
    "x_val = val.drop(columns = ['survived','embark_town'])\n",
    "y_val = val.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "854be425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8057784911717496, 0.8059701492537313)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg4 = LogisticRegression(random_state = seed, max_iter = 400)\n",
    "\n",
    "logreg4.fit(x_train, y_train)\n",
    "\n",
    "logreg4.score(x_train, y_train), logreg4.score(x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f1d329",
   "metadata": {},
   "source": [
    "Alone and pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f447b325",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train[['pclass', 'alone']]\n",
    "y_train = train.survived\n",
    "x_val = val[['pclass', 'alone']]\n",
    "y_val = val.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64c15721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7030497592295345, 0.6791044776119403)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg5 = LogisticRegression(random_state = seed, max_iter = 400)\n",
    "\n",
    "logreg5.fit(x_train, y_train)\n",
    "\n",
    "logreg5.score(x_train, y_train), logreg5.score(x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85da96df",
   "metadata": {},
   "source": [
    "#### 4. Use you best 3 models to predict and evaluate on your validate sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3730fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to do this above because i don't want to input any more code above, and just call the values here.\n",
    "# The "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92b56703",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- alone\nFeature names seen at fit time, yet now missing:\n- age\n- fare\n- sex_male\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m p_train_2 \u001b[38;5;241m=\u001b[39m \u001b[43mlogreg2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m p_val_2 \u001b[38;5;241m=\u001b[39m logreg2\u001b[38;5;241m.\u001b[39mpredict(x_val)\n\u001b[1;32m      3\u001b[0m p_train_3 \u001b[38;5;241m=\u001b[39m logreg3\u001b[38;5;241m.\u001b[39mpredict(x_train)\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_base.py:451\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    450\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 451\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    453\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_base.py:432\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    429\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    430\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 432\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    433\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/sklearn/base.py:579\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    510\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m    516\u001b[0m ):\n\u001b[1;32m    517\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \n\u001b[1;32m    519\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 579\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    584\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    585\u001b[0m         )\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/sklearn/base.py:506\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    502\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m     )\n\u001b[0;32m--> 506\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- alone\nFeature names seen at fit time, yet now missing:\n- age\n- fare\n- sex_male\n"
     ]
    }
   ],
   "source": [
    "p_train_2 = logreg2.predict(x_train)\n",
    "p_val_2 = logreg2.predict(x_val)\n",
    "p_train_3 = logreg3.predict(x_train)\n",
    "p_val_3 = logreg3.predict(x_val)\n",
    "p_train_4 = logreg4.predict(x_train)\n",
    "p_val_4 = logreg4.predict(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf863a5",
   "metadata": {},
   "source": [
    "#### 6. Choose you best model from the validation performation, and evaluate it on the test dataset. How do the performance metrics compare to validate? to train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e81d63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
